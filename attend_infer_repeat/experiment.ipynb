{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path as osp\n",
    "import tensorflow as tf\n",
    "\n",
    "from evaluation import ProgressFig, make_logger\n",
    "from experiment_tools import load, init_checkpoint, parse_flags, print_flags, set_flags_if_notebook, is_notebook\n",
    "from attend_infer_repeat import tf_flags\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define flags\n",
    "\n",
    "tf_flags.DEFINE_string('data_config', 'configs/seq_mnist_data.py', '')\n",
    "tf_flags.DEFINE_string('model_config', 'configs/seq_vimco.py', '')\n",
    "tf_flags.DEFINE_string('results_dir', '../checkpoints', '')\n",
    "tf_flags.DEFINE_string('run_name', 'test_run', '')\n",
    "\n",
    "tf_flags.DEFINE_integer('batch_size', 64, '')\n",
    "\n",
    "tf_flags.DEFINE_integer('summary_every', 1000, '')\n",
    "tf_flags.DEFINE_integer('log_every', 5000, '')\n",
    "tf_flags.DEFINE_integer('save_every', 5000, '')\n",
    "tf_flags.DEFINE_integer('max_train_iter', int(3 * 1e5), '')\n",
    "tf_flags.DEFINE_boolean('resume', False, '')\n",
    "tf_flags.DEFINE_boolean('log_at_start', False, '')\n",
    "\n",
    "tf_flags.DEFINE_float('eval_size_fraction', .01, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_flags_if_notebook(\n",
    "#     data_config='configs/static_mnist_data.py',\n",
    "    seq_len=2,\n",
    "    n_steps_per_image=3,\n",
    "    n_iw_samples=5,\n",
    "#     \n",
    "    log_every=100,\n",
    "    eval_size_fraction=0.01,\n",
    "#     \n",
    "    learning_rate=1e-5,\n",
    "    importance_resample=True,\n",
    "#     \n",
    "    condition_on_latents=True,\n",
    "    condition_on_prev=True,\n",
    "    transition='VanillaRNN',\n",
    "    separate=True,\n",
    "#     prior_around_prev=True,\n",
    "    transition_only_on_object=True,\n",
    "    time_transition='GRU',\n",
    "    step_bias=1.\n",
    "#     \n",
    ")\n",
    "\n",
    "# Parse flags\n",
    "parse_flags()\n",
    "F = tf_flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare enviornment\n",
    "logdir = osp.join(F.results_dir, F.run_name)\n",
    "logdir, flags, resume_checkpoint = init_checkpoint(logdir, F.data_config, F.model_config, F.resume)\n",
    "checkpoint_name = osp.join(logdir, 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Build the graph\n",
    "tf.reset_default_graph()\n",
    "data_dict = load(F.data_config, F.batch_size)\n",
    "air, train_step, global_step = load(F.model_config, img=data_dict.train_img, num=data_dict.train_num)\n",
    "\n",
    "print_flags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "if resume_checkpoint is not None:\n",
    "    print \"Restoring checkpoint from '{}'\".format(resume_checkpoint)\n",
    "    saver.restore(sess, resume_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_writer = tf.summary.FileWriter(logdir, sess.graph)\n",
    "all_summaries = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Logging\n",
    "ax = data_dict['axes']['imgs']\n",
    "factor = F.eval_size_fraction\n",
    "train_batches, valid_batches = [int(data_dict[k]['imgs'].shape[ax] * factor) for k in ('train_data', 'valid_data')]\n",
    "log = make_logger(air, sess, summary_writer, data_dict.train_tensors,\n",
    "                  train_batches, data_dict.valid_tensors, valid_batches)\n",
    "\n",
    "progress_fig = ProgressFig(air, sess, logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, obj_id = sess.run([air.resampled_presence, air.resampled_obj_id])\n",
    "print p.shape\n",
    "print p.sum()\n",
    "print obj_id.shape\n",
    "for i in xrange(3):\n",
    "    print p[:, :, i].sum()\n",
    "\n",
    "for i in xrange(64):\n",
    "    for t in xrange(p.shape[0]):\n",
    "        print '\\t' * t, p[0, i, :, 0], obj_id[0, i, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress_fig.plot_all(save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_itr = sess.run(global_step)\n",
    "print 'Starting training at iter = {}'.format(train_itr)\n",
    "\n",
    "\n",
    "if F.log_at_start or train_itr == 0:\n",
    "    log(train_itr)\n",
    "    if not is_notebook():\n",
    "        progress_fig.plot_all(train_itr)\n",
    "\n",
    "while train_itr < F.max_train_iter:\n",
    "\n",
    "    train_itr, _ = sess.run([global_step, train_step])\n",
    "\n",
    "    if train_itr % F.summary_every == 0:\n",
    "        summaries = sess.run(all_summaries)\n",
    "        summary_writer.add_summary(summaries, train_itr)\n",
    "\n",
    "    if train_itr % F.log_every == 0:\n",
    "        log(train_itr)\n",
    "\n",
    "    if train_itr % F.save_every == 0:\n",
    "        saver.save(sess, checkpoint_name, global_step=train_itr)\n",
    "        progress_fig.plot_all(train_itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# progress_fig.plot_all(save=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
